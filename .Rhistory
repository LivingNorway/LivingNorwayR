# Retrieve all the GBIF classes and their members
allGBIFClassList <- retrieveGBIFClassSpecifications("all", TRUE)
xmlLinks
testOut <- do.call(c, lapply(X = c(dirLinks, xmlLinks), FUN = function(curLink, curBaseAddress, termList) {
outVals <- list()
if(grepl("\\.xml$", curLink, perl = TRUE)) {
# If the link is to a XML file then scrape the property information from it
outVals <- list(createGBIFClass(paste(curBaseAddress, curLink, sep = ""), termList))
} else if(grepl("/$", curLink, perl = TRUE)) {
# If the link is to another folder then call the function recursively
outVals <- findGBIFClasses(paste(curBaseAddress, curLink, sep = ""), termList)
}
outVals
}, curBaseAddress = specAddress, termList = termList))
testOut
lapply(X = testOut, FUN = function(curEl) { curEl$termInfo })
curDoc <- read_xml("https://rs.gbif.org/extension/ggbn/cloning.xml")
curDoc
xml_attr(curDoc, "relation")
xml_attrs(curDoc)
xml_attr(curDoc, "rowType")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCTerm.R', echo=TRUE)
library(R6)
library(xml2)
library(zip)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCTerm.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/DwCTermList.R', echo=TRUE)
names(DwCTermList)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/GBIFClassList.R', echo=TRUE)
names(GBIFExtClassList)
names(GBIFCoreClassList)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/DwCClassList.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/createClassInfrastructure.R', echo=TRUE)
createGBIFClassInfrastructure("C:/Users/joseph.chipperfield/OneDrive - NINA/Work/LivingNorway/LivingNorwayR_GitHub/R")
stop("hello", "joe")
localeToCharset(Sys.getlocale("LC_CTYPE"))
?unzip
unzip("ssngis")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCTerm.R', echo=TRUE)
library(R6)
library(xml2)
library(zip)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCTerm.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCGeneric.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEvent.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEnvironmentLookup.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEnvironmentLookup.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFMeasurementOrFact.R', echo=TRUE)
# ====== 1.1. Create test data ======
# Initialise two data frames representing test data to convert into a Darwin core archive
# Initialise a data frame to be the core type
testCoreFrame <- data.frame(
idCode = c(1233:1236),
lat = c(60.418292, 60.38143, 63.41407, 59.82642),
long = c(5.234457, 5.33081, 10.40666, 10.69530)
)
# Initialise a data frame to be the extension type
testExtFrame <- data.frame(
idCode = 1:4,
relatedTo = testCoreFrame$idCode,
count = c(4, 6, 8, 9),
valType = rep("count", 4)
)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
# Source file to generate the list of classes (and the terms associated with them) that are supported by GBIF
# ------ 1. RETRIEVE CLASS SPECIFICATIONS AND REGISTER AS DATA ------
# Retrieve the class specifications for both the core and extension classes
GBIFCoreClassList <- retrieveGBIFClassSpecifications("core", TRUE)
GBIFExtClassList <- retrieveGBIFClassSpecifications("extension", TRUE)
# Source file to generate the list of Darwin core terms used by some package functions
# ------ 1. RETRIEVE TERM SPECIFICATIONS AND REGISTER AS DATA ------
# Retrieve the term specifications
DwCTermList <- retrieveDwCTermSpecifications(TRUE, TRUE)
# Source file to generate the list of classes (and the terms associated with them) in Darwin core used by some package functions
# ------ 1. RETRIEVE CLASS SPECIFICATIONS AND REGISTER AS DATA ------
# Retrieve the class specifications
DwCClassList <- retrieveDwCClassSpecifications(TRUE)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
getGBIFEventTerm
getGBIFEventTerm()
getGBIFEventMembers()
debug(GBIFEvent$new)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
debug(GBIFEvent$initialize)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEvent.R', echo=TRUE)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
idColumnInfo
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCGeneric.R', echo=TRUE)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
measurementExtOb <- GBIFMeasurementOrFact$new(testExtFrame, "relatedTo", measurementID = "idCode", measurementUnit = "valType", measurementValue = "count")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFMeasurementOrFact.R', echo=TRUE)
measurementExtOb <- GBIFMeasurementOrFact$new(testExtFrame, "relatedTo", measurementID = "idCode", measurementUnit = "valType", measurementValue = "count")
createGBIFClassInfrastructure("C:/Users/joseph.chipperfield/OneDrive - NINA/Work/LivingNorway/LivingNorwayR_GitHub/R")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/createClassInfrastructure.R', echo=TRUE)
createGBIFClassInfrastructure("C:/Users/joseph.chipperfield/OneDrive - NINA/Work/LivingNorway/LivingNorwayR_GitHub/R")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEvent.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFMeasurementOrFact.R', echo=TRUE)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- GBIFEvent$new(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
measurementExtOb <- GBIFMeasurementOrFact$new(testExtFrame, "relatedTo", measurementID = "idCode", measurementUnit = "valType", measurementValue = "count")
# ====== 1.3. Build the Darwin core archive ======
archiveOb <- DwCArchive$new(eventCoreOb, measurementExtOb)
# Create a temporary location to store the Darwin core archive file
testLoc <- paste(tempfile(), ".zip", sep = "")
archiveOb$exportAsDwCArchive(testLoc)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
metaFileContents
xml_attrs(metaFileContents)
xml_children(metaFileContents)
curChild <- xml_children(metaFileContents)
curChild <- xml_children(metaFileContents)[1]
curChild
curChild <- xml_children(metaFileContents)[[1]]
curChild
xml_attrs(curChild)
xml_attr(curChild, "gjoa")
?read.table
xml_find_all(curChild, "//files/location")
xml_find_all(curChild, "//location")
?xml_find_all
xml_find_all(curChild, "//files")
xml_find_all(curChild, "//files/")
xml_find_all(curChild, "/files/location")
xml_find_all(curChild, "files/location")
xml_find_all(xml_children(curChild), "files/location")
xml_children(curChild)
xml_find_all(curChild, "//files")
curChild
xml_find_all(curChild, ".//files")
xml_find_all(curChild, ".//")
xml_find_all(curChild, ".//files")
xml_find_all(curChild, "./files/location")
xml_find_all(curChild, ".//files/location")
xml_find_all(curChild, "..//files/location")
xml_ns(curChild)
xml_find_all(xml_children(curChild), ".//files/location")
xml_find_all(xml_children(curChild), "//files/location")
xml_find_all(xml_children(curChild), "files/location")
xml_find_all(xml_children(curChild), "./files/location")
xml_find_all(xml_children(curChild), "../files/location")
xml_find_all(xml_children(curChild), ".//location/files")
xml_find_all(xml_children(curChild), ".//location")
xml_find_all(curChild, ".//location")
curChild
xml_find_all(curChild, "./core//location")
xml_find_all(curChild, "./core/files/location")
xml_find_all(curChild, "core/files/location")
xml_find_all(curChild, "/files/location")
xml_find_all(curChild, "//*")
xml_children(curChild)
xml_find_all(xml_children(curChild), "/files")
xml_find_all(xml_children(curChild)[1], "/files")
xml_find_all(xml_children(curChild)[1], "child/files")
xml_find_all(curChild, "child/files")
xml_find_all(curChild, "./files")
xml_find_all(curChild, ".//files")
curChild
xml_find_all(curChild, ".//*/files")
xml_find_all(curChild, "./*/files")
xml_find_all(curChild, ".//location")
xml_find_all(curChild, "descendant::ocation")
xml_find_all(curChild, ".//descendant::ocation")
xml_find_all(curChild, "./descendant::ocation")
xml_find_all(curChild, "./descendant::location")
xml_find_all(curChild, ".//descendant::location")
xml_find_all(curChild, "//*/files")
xml_find_all(curChild, "//*//files")
xml_find_all(curChild, ".//files")
xml_find_all(curChild, "child::files")
xml_find_all(curChild, "./child::files")
curChild
curNode <- xml_child(curChild)
curNode
xml_attrs(curChild)
attr(curChild)
attributes(curChild)
curNode
xml_find_all(curNode, "./location")
xml_find_all(curNode, ".//location")
?xpathSApply
xml_path(curChild)
xml_type(curChild)
?xml_type
xml_name(curChild)
unlist(lapply(X = xml_children(curChild), FUN = function(curNode) {
filePaths <- c()
if(xml_name(curNode) == "files") {
filePaths <- sapply(X = xml_children(curNode), FUN = function(fileNode) {
xml_text(fileNode)
})
}
filePaths
}))
fileName <- unlist(lapply(X = xml_children(curChild), FUN = function(curNode) {
filePaths <- c()
if(xml_name(curNode) == "files") {
filePaths <- sapply(X = xml_children(curNode), FUN = function(fileNode) {
xml_text(fileNode)
})
}
filePaths
}))
fieldEnc
curChild
xml_children(metaFileContents)
# Function to return special characters
returnSpecialChars <- function(inChar) {
gsub("\\t", "\t", gsub("\\r", "\r", gsub("\\n", "\n", inChar, fixed = TRUE), fixed = TRUE), fixed = TRUE)
}
# Retrieve the relevant attributes from the metafile
qualName <- xml_attr(curChild, "rowType")
if(is.na(qualName)) {
stop("error encountered importing Darwin core archive: unspecified table type")
}
fieldTerm <- xml_attr(curChild, "fieldsTerminatedBy")
if(is.na(fieldTerm)) {
fieldTerm <- ","
} else {
fieldTerm <- returnSpecialChars(fieldTerm)
}
lineTerm <- xml_attr(curChild, "linesTerminatedBy")
if(is.na(lineTerm)) {
lineTerm <- "\n"
} else {
lineterm <- returnSpecialChars(lineTerm)
}
fieldEnc <- xml_attr(curChild, "fieldsEnclosedBy")
if(is.na(fieldEnc)) {
fieldEnc <- "\""
} else {
fieldEnc <- returnSpecialChars(fieldEnc)
}
fileEnc <- xml_attr(curChild, "encoding")
if(is.na(fileEnc)) {
fileEnc <- "UTF-8"
} else {
fileEnc <- returnSpecialChars(fileEnc)
}
headIgnore <- xml_attr(curChild, "ignoreHeaderLines")
if(is.na(headIgnore)) {
headIgnore <- 0
} else {
headIgnore <- as.integer(headIgnore)
}
dateFormat <- xml_attr(curChild, "dateFormat")
if(is.na(dateFormat)) {
dateFormat <- "YYYY-MM-DD"
}
fileName
# Sanity check the file input
if(length(fileName) <= 0) {
stop("error encountered importing Darwin core archive: no file specified for core or extension table")
} else if(length(fileName) > 1) {
stop("error encountered importing Darwin core archive: multiple files specified for core or extension table")
}
fileName <- file.path(tempLoc, fileName)
if(!file.exists(file.path(temp))) {
stop("error encountered importing Darwin core archive: specified file for core or extension table does not exist in the archive")
}
if(!file.exists(fileName)) {
stop("error encountered importing Darwin core archive: specified file for core or extension table does not exist in the archive")
}
fileName
xml_name(curChild)
# Sanity check the node type
fileType <- xml_name(curChild)
if(!(fileType %in% c("core", "extension"))) {
stop("error encountered importing Darwin core archive: file type is not core or extension in meta XML specifiction")
}
mappedTerms <- lapply(X = xml_children(curChild), FUN = function(curNode) {
outMap <- NULL
if(xml_name(curNode) == "field") {
# Retrieve the attributes associated with the current node
outMap <- list(
term = xml_attr(curNode, "term"),
default = xml_attr(curNode, "default"),
index = xml_attr(curNode, "index"),
vocabulary = xml_attr(curNode, "vocabulary"),
shortName = NA
)
# Sanity check the term attribute
if(is.na(outMap$term)) {
stop("error encountered importing Darwin core archive: term attribute not set in a field tag")
} else {
# Retrieve the short name of the term
outMap$shortName <- gsub("^.*[\\/\\:]", "", outMap$term, perl = TRUE)
}
}
outMap
})
mappedTerms
mappedTerms[!sapply(X = mappedTerms, FUN = is.null)]
mappedTerms <- mappedTerms[!sapply(X = mappedTerms, FUN = is.null)]
fileName
?read.table
read.table(fileName, header = TRUE, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
fieldTerm
fieldTerm <- returnSpecialChars(fieldTerm)
lineterm <- returnSpecialChars(lineTerm)
fieldEnc <- returnSpecialChars(fieldEnc)
fieldTerm
inTableData <- read.table(fileName, header = TRUE, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
inTableData
readLines(fileName)
?readLines
allText <- paste(readLines(fileName), collapse = "\n")
allText
lineTerm
lineterm <- returnSpecialChars(lineTerm)
lineTerm
returnSpecialChars <- function(inChar) {
gsub("\\t", "\t", gsub("\\r", "\r", gsub("\\n", "\n", inChar, fixed = TRUE), fixed = TRUE), fixed = TRUE)
}
returnSpecialChars(lineTerm)
lineterm <- returnSpecialChars(lineTerm)
lineTerm
lineTerm <- returnSpecialChars(lineTerm)
gsub(lineTerm, "\n", paste(readLines(fileName), collapse = "\n"), fixed = TRUE)
?read.table
# Ensure that the proper line delimiter is used
allText <- gsub(lineTerm, "\n", paste(readLines(fileName), collapse = "\n"), fixed = TRUE)
read.table(text = allText, header = TRUE, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
read.table(text = allText, header = FALSE, skip = headIgnore, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
headIgnore
?readLines
?read.table
read.table(text = allText, header = FALSE, skip = 0, nrows = 1, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
possCols <- read.table(text = allText, header = FALSE, skip = 0, nrows = 1, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
possCols <- as.matrix(possCols)[1, ]
possCols
ncol(inTableData)
!any(duplicated(possCols))
colnames(inTableData) <- possCols
inTableData
# Ensure that the proper line delimiter is used
allText <- gsub(lineTerm, "\n", paste(readLines(fileName, encoding = fileEnc), collapse = "\n"), fixed = TRUE)
# Import the data from the file location
inTableData <- read.table(text = allText, header = FALSE, skip = headIgnore, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
if(headIgnore == 1) {
# If only one line has been ignored at the start of the file then check to see whether those entries can be coerced into column names
possCols <- read.table(text = allText, header = FALSE, skip = 0, nrows = 1, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
possCols <- as.character(as.matrix(possCols)[1, ])
if(length(possCols) == ncol(inTableData) && !any(duplicated(possCols))) {
colnames(inTableData) <- possCols
}
}
inTableData
headIgnore
allText <- gsub(lineTerm, "\n", paste(readLines(fileName, encoding = fileEnc), collapse = "\n"), fixed = TRUE)
# Import the data from the file location
inTableData <- read.table(text = allText, header = FALSE, skip = as.integer(headIgnore), sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
if(as.integer(headIgnore) == 1) {
# If only one line has been ignored at the start of the file then check to see whether those entries can be coerced into column names
possCols <- read.table(text = allText, header = FALSE, skip = 0, nrows = 1, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
possCols <- as.character(as.matrix(possCols)[1, ])
if(length(possCols) == ncol(inTableData) && !any(duplicated(possCols))) {
colnames(inTableData) <- possCols
}
}
inTableData
possCols
length(possCols) == ncol(inTableData)
!any(duplicated(possCols))
length(possCols) == ncol(inTableData) && !any(duplicated(possCols))
allText <- gsub(lineTerm, "\n", paste(readLines(fileName, encoding = fileEnc), collapse = "\n"), fixed = TRUE)
# Import the data from the file location
inTableData <- read.table(text = allText, header = FALSE, skip = as.integer(headIgnore), sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
if(as.integer(headIgnore) == 1) {
# If only one line has been ignored at the start of the file then check to see whether those entries can be coerced into column names
possCols <- read.table(text = allText, header = FALSE, skip = 0, nrows = 1, sep = fieldTerm, quote = fieldEnc, na.strings = "", fileEncoding = fileEnc)
possCols <- as.character(as.matrix(possCols)[1, ])
if(length(possCols) == ncol(inTableData) && !any(duplicated(possCols))) {
colnames(inTableData) <- possCols
}
}
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
inTableData
curChild
?date
?strptime
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/createClassInfrastructure.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/createClassInfrastructure.R', echo=TRUE)
createGBIFClassInfrastructure("C:/Users/joseph.chipperfield/OneDrive - NINA/Work/LivingNorway/LivingNorwayR_GitHub/R")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/data-raw/createClassInfrastructure.R', echo=TRUE)
createGBIFClassInfrastructure("C:/Users/joseph.chipperfield/OneDrive - NINA/Work/LivingNorway/LivingNorwayR_GitHub/R")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEvent.R', echo=TRUE)
# ====== 1.1. Create test data ======
# Initialise two data frames representing test data to convert into a Darwin core archive
# Initialise a data frame to be the core type
testCoreFrame <- data.frame(
idCode = c(1233:1236),
lat = c(60.418292, 60.38143, 63.41407, 59.82642),
long = c(5.234457, 5.33081, 10.40666, 10.69530)
)
# Initialise a data frame to be the extension type
testExtFrame <- data.frame(
idCode = 1:4,
relatedTo = testCoreFrame$idCode,
count = c(4, 6, 8, 9),
valType = rep("count", 4)
)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- initializeGBIFEvent(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
debug(initializeGBIFEvent)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFMeasurementOrFact.R', echo=TRUE)
debug(initializeGBIFEvent)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- initializeGBIFEvent(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
defDateFormat
defDateFormat
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCGeneric.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFEvent.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/GBIFMeasurementOrFact.R', echo=TRUE)
# ====== 1.1. Create test data ======
# Initialise two data frames representing test data to convert into a Darwin core archive
# Initialise a data frame to be the core type
testCoreFrame <- data.frame(
idCode = c(1233:1236),
lat = c(60.418292, 60.38143, 63.41407, 59.82642),
long = c(5.234457, 5.33081, 10.40666, 10.69530)
)
# Initialise a data frame to be the extension type
testExtFrame <- data.frame(
idCode = 1:4,
relatedTo = testCoreFrame$idCode,
count = c(4, 6, 8, 9),
valType = rep("count", 4)
)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- initializeGBIFEvent(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCGeneric.R', echo=TRUE)
# ====== 1.2. Convert test data to augmented frames ======
eventCoreOb <- initializeGBIFEvent(testCoreFrame, "idCode", eventID = "idCode", decimalLatitude = "lat", decimalLongitude = "long")
measurementExtOb <- initializeGBIFMeasurementOrFact(testExtFrame, "relatedTo", measurementID = "idCode", measurementUnit = "valType", measurementValue = "count")
# ====== 1.3. Build the Darwin core archive ======
archiveOb <- DwCArchive$new(eventCoreOb, measurementExtOb)
# Create a temporary location to store the Darwin core archive file
testLoc <- paste(tempfile(), ".zip", sep = "")
archiveOb$exportAsDwCArchive(testLoc)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
inTableData
mappedTerms
(1:5)[-3]
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
qualName
GBIFClassLookup(qualName)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
mappedTerms
mappedParams
mappedParams
classEnv
GBIFTableOb
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
GBIFTableOb
attr(GBIFTableOb, "fileType")
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
outTypes <- sapply(X = fileList, FUN = function(curFile) { attr(curFile, "fileType") })
outTypes
coreIndex <- which(outTypes == "core")
coreIndex
which(outTypes == "gianiv")
joe <- c(5)
joe[-1]
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
inArchiveOb
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
# ===== 1.5. Retrieve the original data frames from the Darwin core archive ======
outTestCoreFrame <- inArchiveOb$getCoreTable()$exportAsDataFrame()
outTestExtFrame <- inArchiveOb$getExtensionTables(1)$exportAsDataFrame()
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
outTestExtFrame <- inArchiveOb$getExtensionTables(1)$exportAsDataFrame()
source('~/Work/LivingNorway/LivingNorwayR_GitHub/R/DwCArchive.R', echo=TRUE)
outTestExtFrame <- inArchiveOb$getExtensionTables(1)$exportAsDataFrame()
# ===== 1.4. Import from the Darwin core archive ======
inArchiveOb <- DwCArchive$new(testLoc)
# ===== 1.5. Retrieve the original data frames from the Darwin core archive ======
outTestCoreFrame <- inArchiveOb$getCoreTable()$exportAsDataFrame()
outTestExtFrame <- inArchiveOb$getExtensionTables(1)$exportAsDataFrame()
outTestExtFrame <- inArchiveOb$getExtensionTables()[[1]]$exportAsDataFrame()
outTestExtFrame
outTestCoreFrame

---
title: "Mapping data to Darwin Core using the LivingNorwayR package"
subtitle: "Part 1"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mapping data to Darwin Core using the LivingNorwayR package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: REFERENCES.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

{LivingNorwayR} (@LivingNorwayR) is our newly developed R (@R) package that allows the user to create a Darwin Core Standard (https://dwc.tdwg.org/) compliant data archive ("a data package") for their biodiversity data.

We assume that the reader knows something about the Darwin Core Standards (a very basic understanding is okay). Have a look at our vignette ["Handling Darwin Core Files With Living Norway:  Example Using the TOV-E Dataset"](https://livingnorway.github.io/LivingNorwayR/articles/LNWorkshopExample_TOV-E.html) for a good overview.

Here we will run through an example of how to map biodiversity data to the Darwin Core terms using {LivingNorwayR}. 

## Load the packages we need

As {LivingNorwayR} is still in development (although now firmly in the testing stage of development) we need to install it from GitHub. You can do this using the following code.

```{r install packages, eval=FALSE}
list.of.packages <- c("tidyverse", "devtools", "uuid")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
################################
devtools::install_github("LivingNorway/LivingNorwayR")
```


```{r load the libraries we need, echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse, quietly = TRUE)
library(LivingNorwayR)
library(palmerpenguins)
```

## The data

Let's use a well-known and openly available dataset from R; The Palmer Penguins dataset (@palmer). 

This dataset consists of observations and measurements of three different species of penguin in Antarctica [Artwork by Allison Horst]. 

![The three species of penguin.Artwork by @allison_horst](images/penguins.png)
We can have a quick look at the dataset.

```{r,echo=TRUE, warning=FALSE, message=FALSE}
penguin_data<-palmerpenguins::penguins_raw

#clean the column names
penguin_data<-penguin_data %>% 
  janitor::clean_names()

penguin_data %>% 
  head() %>% 
  kableExtra::kable() %>% 
  kableExtra::kable_styling("striped", full_width = F) %>% 
 kableExtra::scroll_box(width = "800px", height = "200px")
```


Each row is a single individual penguin of one of the three species. There are measures of body size (bill and flipper lengths), sex (male or female), as well as information on egg laying date and stable isotope analysis from blood samples.

![Bill length and depth measurements for each penguin.Artwork by Allison Horst](images/culmen_depth.png)

## Mapping to Darwin Core

### *Deciding on the Core*

The first task is to decide how our data will be structured. We need to decide what class of file will be our core data file in the Darwin Core Archive. {LivingNorwayR} can give us a list of the potential core classes that could best describe our data.

```{r}
LivingNorwayR::getGBIFCoreClasses()
```

The choice of which table should be the core table depends on how much information the data contains and also how the data owner wishes to share the data. There can be several different ways to structure the Darwin Core Archive that are still valid. 

As each of the rows represents a sampling event we can use the Event table as our core. 

*Deciding on the extensions* 

We have species data for each Event and we can include an Occurrence table as an extension. 

We can get a list of the other extension classes that are supported by GBIF using the following code:    

```{r}
LivingNorwayR::getGBIFExtensionClasses()[1:6] # Truncated
```

From this list the other extension class we could consider including in our Darwin Core Archive is the Measurement Or Fact table. This will hold information about the measurements taken. 

## The Event Core

We can get a list of the terms associated with an Event by using this code:

```{r}
getGBIFEventMembers()[1:6] # Truncated
```

From the above list of Event Members we can select those that are most relevant for our dataset. *We do not have to use them all!* GBIF recommends some required and suggested terms for Events here (https://www.gbif.org/data-quality-requirements-sampling-events). These include **eventID**, **eventDate**, **samplingProtocol**, **samplingSizeValue** and **samplingSizeUnit** as required. Some of the strongly recommended elements that it makes sense for us to include are **parentEventID**, **countryCode**, **locationID**	**decimalLatitude**, **decimalLongitude**,
**geodeticDatum** and **coordinateUncertaintyInMeters**. We can also add **type**,**datasetName**, **ownerInstitutionCode**, **country**, **year**, **month** and **day**.


### *Parent Events*

Each event is a part of a higher level Event which is referred to as a Parent Event. The Parent Event in our case is represented by the "studyName" column. This represents a unique expedition carried out at a separate time. We can include this information in the Event table. 

The Parent Events are three different expeditions in different years. 

Each Parent Event needs a unique persistent identifier, **parentEventID**, which we can obtain from the {uuid} package (@uuid).   

```{r}
penguin_data=penguin_data %>%
  group_by(study_name) %>%
  mutate(
    parentEventID = uuid::UUIDgenerate(use.time = FALSE)
  )
```

There are different date ranges for each parent event and these need to be added as an **eventDate**. 

```{r}
# Event Date for parentIDs

parent_penguinEvent=penguin_data %>%
  group_by(parentEventID) %>%
  summarise(min=min(date_egg), max=max(date_egg)) %>%
  mutate(eventDate=paste0(min,"/", max)) %>% mutate(eventID=parentEventID)

```

We can also add some wider scale geographic information to the parent events. Such as **continent** and **islandGroup**.

```{r}
# Event continent and islandGroup for parentIDs
parent_penguinEvent=parent_penguinEvent %>%
  mutate(continent="Antarctica") %>%
  mutate(islandGroup="Palmer Archipelago") %>%
  select(!c(min,max))

```

### *Event*

Let's start with the **type**, **datasetName** and  **ownerInstitutionCode**. The **type** is "Event", the **datasetName** is "Palmer-penguins" and the Palmer Station Antarctica LTER **ownerInstitutionCode** is "PAL". 

```{r}
penguin_data=penguin_data %>% 
  mutate(ownerInstitutionCode="PAL",
         type="Event",
         datasetName="Palmer-penguins")
```

Each Event also needs a unique identifier (**eventID**) and we can use the same approach as above. This time as each row is an Event we need to make sure the dataframe is ungrouped.

```{r}
penguin_data=penguin_data %>% 
  ungroup() %>%
  rowwise()%>%
    mutate(
    eventID = uuid::UUIDgenerate(use.time = FALSE)
  )
```

Again we can include an **eventDate** for each event. For the penguins data we do not have a true date of the sampling event, but we do have a egg laying date and we shall use this for illustrative purposes. We can also extract the day, month and year information at the same time.

```{r}
penguin_data=penguin_data %>% 
    mutate(
    eventDate = date_egg) %>% 
  mutate(day=lubridate::day(date_egg),
         month=lubridate::month(date_egg),
         year=lubridate::year(date_egg))

```
As each event is a sample in the penguins dataset where they measured a individual penguin we can set the **sampleSizeValue** as 1. The **sampleSizeUnit** can be "Adult penguin".

```{r}
penguin_data=penguin_data %>% 
  mutate(sampleSizeValue=1) %>% 
  mutate(sampleSizeUnit="Adult penguin")
```

We can get the **samplingProtocol** for each event by looking at the original data package (links can be found when you type ??palmerpenguins::penguins_raw in to the R Console). All three parent events have the same protocol.  

```{r}
penguin_data=penguin_data %>% 
  mutate(samplingProtocol= "Each season, study nests, where pairs of adults were present, were individually marked and chosen before the onset of egg-laying, and consistently monitored. When study nests were found at the one-egg stage, both adults were captured to obtain blood samples used for molecular sexing and stable isotope analyses, and measurements of structural size and body mass. At the time of capture, each adult penguin was quickly blood sampled (~1 ml) from the brachial vein using a sterile 3 ml syringe and heparinized infusion needle. Collected blood was stored in 1.5 ml micro-centrifuge tubes that were kept cool. In the field, a small amount of whole blood was smeared on clean filter paper stored in a 1.5 ml micro-centrifuge tube for molecular sexing. Measurements of culmen length and depth (using dial calipers ± 0.1 mm), right flipper (using a ruler ± 1 mm), and body mass (using 5 kg ± 25 g or 10 kg ± 50 g Pesola spring scales and a weigh bag) were obtained to quantify body size variation. After handling, individuals at study nests were further monitored to ensure the pair reached clutch completion, i.e., two eggs. Molecular analyses were conducted at Simon Fraser University following standard PCR protocols, and stable isotope analyses were conducted at the Stable Isotope Facility at the University of California, Davis using an elemental analyzer interfaced with an isotope ratio mass spectrometer")
```

**countryCode** is the two letter standard (using ISO 3166-1-alpha-2) code for a country. Antarctica, defined as the territories south of 60°S is given the code AQ. 

```{r}
penguin_data =penguin_data %>% 
  mutate(countryCode="AQ",
         country="Antarctica")
```

The **locationID** can be a global unique identifier or an identifier specific to the data set. We have the region and island for the penguins data so we can use these to develop a data specific identifier. 

```{r}
penguin_data=penguin_data %>% 
  mutate(locationID=paste0(region, "_", island))
```

We are not provided with precise coordinates (**decimalLatitude**, **decimalLongitude**) for the samples in the penguin data. However, we can get the centroid for each island; Torgersen is at -64.77308, -64.07413; Biscoe is at -65.4333316 -65.499998; and Dream is at -64.7333333, -64.2333333. The **geodeticDatum** is WGS 84 (this is the default assumed by GBIF if you do not add this field explicitly).

```{r}
penguin_data=penguin_data %>% 
  mutate(decimalLatitude= 
           case_when(
             island=="Torgersen"~-64.77308,
             island=="Biscoe"~-65.4333316,
             island=="Dream"~-64.7333333,
             TRUE~as.numeric(NA))
  ) %>% 
  mutate(decimalLongitude= 
           case_when(
             island=="Torgersen"~-64.07413,
             island=="Biscoe"~-65.499998,
             island=="Dream"~-64.2333333,
             TRUE~as.numeric(NA))
    
  ) %>% 
  mutate(geodeticDatum="WGS 84")

```

As the coordinates are just the centroid for the island we need to include some measure of uncertainty (**coordinateUncertaintyInMeters**). We can guess the uncertainity by looking at the size of the islands. Torgersen is 400 m wide; Biscoe is around 500m wide and Dream is also around 400 m wide. 


```{r}
penguin_data=penguin_data %>% 
  mutate(coordinateUncertaintyInMeters= 
           case_when(
             island=="Torgersen"~400,
             island=="Biscoe"~500,
             island=="Dream"~400,
             TRUE~as.numeric(NA))
  )
```

Finally, we can create the Event core by selecting those elements that we have listed above. 

```{r}
eventDF=penguin_data %>% 
  select(c("datasetName",
           "ownerInstitutionCode",
           "parentEventID",
           "eventID",
           "samplingProtocol",
           "sampleSizeValue",
           "sampleSizeUnit",
           "eventDate",
           "year",
           "month",
           "day",
           "locationID",
           "country",
           "countryCode",
           "decimalLatitude",
           "decimalLongitude",
           "geodeticDatum",
           "coordinateUncertaintyInMeters"))
```

Then we need to add in the Parent Events in to the Event dataframe.

```{r}
eventDF=eventDF %>% 
  mutate(continent=NA) %>% 
  mutate(islandGroup=NA) %>% 
  mutate(eventDate=as.character(eventDate)) %>% bind_rows(parent_penguinEvent)
```

The final stage is to initialise an event object in the {livingNorwayR} package - this will be used later to build the Darwin Core compliant data package.

```{r}
GBIF_Event=initializeGBIFEvent(eventDF, idColumnInfo = "eventID", nameAutoMap = TRUE)
```


## The Occurrence extension

We can find the supported terms for the Occurrence extension by using the following function.

```{r}
getGBIFOccurrenceMembers()[1:6]#Truncated
```
GBIF also has a list of required and recommended terms for Occurrence data (https://www.gbif.org/data-quality-requirements-occurrences). The required terms are 
**occurrenceID**, **basisOfRecord**,**scientificName**,	**eventDate** (included in the event core). The recommended terms include **countryCode**, **taxonRank**,**kingdom**,	**decimalLatitude**, **decimalLongitude**,	**geodeticDatum**,	**coordinateUncertaintyInMeters**,**individualCount**, **organismQuantity** and **organismQuantityType**, some of which are included in the event core. 

We will also add some more information including **type**, **collectionCode**, 
**organismQuantity**, **organismQuantityType**,
**phylum**, **class**, **order**, **family**, **genus**, **vernacularName** and **sex**.

The **type** is an "Occurrence". The **collectionCode** can be "Palmer Station Antarctica LTER" and the **occurrenceID** should be a globally unique identifier. 

```{r}
penguin_data=penguin_data %>% 
  mutate(type="Occurrence",
    collectionCode="Palmer Station Antarctica LTER") %>% 
  mutate(occurrenceID=uuid::UUIDgenerate(use.time = FALSE))
```

The **basisOfRecord** records how the observation was made (e.g. **PreservedSpecimen**, **FossilSpecimen**, **LivingSpecimen**, **MaterialSample**, **Event**, **HumanObservation**, **MachineObservation**, etc.)

```{r}
klippy::klippy(position = "right")
penguin_data=penguin_data %>% 
  mutate(basisOfRecord="HumanObservation")
  
```
**organismQuantity** and  **organismQuantityType**, are 1 individual penguin. 

```{r}
penguin_data=penguin_data %>% 
  mutate(organismQuantity= 1,
         organismQuantityType= "individual")
```

For the **scientificName** and **vernacularName** we can use the species name from the original data set. 

```{r}
penguin_data=penguin_data %>% 
  mutate(scientificName=gsub("[\\(\\)]", "", regmatches(species, gregexpr("\\(.*?\\)",species))[[1]]),
         vernacularName=gsub("\\s*\\([^\\)]+\\)","",species))
```

**taxonRank**, **kingdom**, **phylum**, **class**, **order**, **family** and  **genus** all relate to the scientific name of the species. The **taxonRank** will be **species** because we have identified the penguins to the species level. 

```{r}
penguin_data=penguin_data %>% 
  mutate(kingdom="Animalia",
         phylum="Chordata",
         class="Aves",
         order=	"Sphenisciformes",
         family= "Spheniscidae",
         genus="Pygoscelis",
         ) %>% 
  mutate(taxonRank="species")
```

Finally, as we did with the Event core, we can create the occurrence extension by selecting those elements that we have listed above and create a {livingNorwayR} object.


```{r}
occ_ext=penguin_data %>% 
  select(type,collectionCode,basisOfRecord,occurrenceID, organismQuantity, organismQuantityType, 
         eventID, eventDate, scientificName,kingdom, phylum, class, order, family, genus,vernacularName,taxonRank, sex)
```


```{r}
GBIF_Occ=initializeGBIFOccurrence(occ_ext, idColumnInfo = "occurrenceID",nameAutoMap = TRUE )
```

## The Measurement or Fact extension

Our final extension is the "Measurement or Fact extension". We can look at the definition of this extension using the following code:

```{r}
getGBIFExtensionClasses()$GBIFMeasurementOrFact
```

GBIF has a list of properties for this extension (https://tools.gbif.org/dwca-validator/extension.do?id=dwc:MeasurementOrFact). These include **measurementID**
**measurementType**, **measurementValue**, **measurementAccuracy**, **measurementUnit**, **measurementDeterminedDate**, **measurementDeterminedBy**, **measurementMethod** and **measurementRemarks**, none of which are required. 

Let's start with the **measurementID**. We should also include the **occurrenceID** and **eventID** so that we know which individual and in which sampling event the measurements were taken.

```{r}
M_or_f=penguin_data %>% 
  mutate(measurementID=uuid::UUIDgenerate(use.time = FALSE))

```

There are a number of measurements that we can include in this extension. 

```{r}
M_or_f=M_or_f %>% 
  select(measurementID,parentEventID,occurrenceID,eventID,
         culmen_length_mm, culmen_depth_mm, delta_13_c_o_oo, delta_15_n_o_oo, body_mass_g, flipper_length_mm)
```

We need to pivot the data so that all the measurement types go in to a single column called **measurementType**. All the measurements go in to a column called **measurementValue**.

```{r}
M_or_f=M_or_f %>% 
  pivot_longer(cols = c(culmen_length_mm, culmen_depth_mm, delta_13_c_o_oo, delta_15_n_o_oo, body_mass_g, flipper_length_mm), names_to="measurementType",
               values_to = "measurementValue"
  ) %>% 
  drop_na(measurementValue)

```

Finally we create a measurement or fact object using {livingNorwayR}. 

```{r}
GBIF_Measure=initializeGBIFMeasurementOrFact(M_or_f, idColumnInfo = "measurementID", nameAutoMap = TRUE)
```

## Next steps

The next step is to write the metadata for the data. We can do this using the {LivingNorwayR} package and in the next tutorial we will show you how to do this (LINK TO PART TWO) and how to bring it all together in to a data package. 


## References
